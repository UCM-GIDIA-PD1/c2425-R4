 # UFC Predictor: Sistema de predicci칩n para la UFC

### Proyecto Datos I

### 1. Descripci칩n de los objetivos

El objetivo de este proyecto es desarrollar dos sistemas de aprendizaje autom치tico. Uno predice el ganador de un combate de la UFC bas치ndose en datos de la pelea para conocer cual es el ganador justo o como una herramienta que puedan usar jueces de la UFC. 

El segundo predice el ganador usando informaci칩n previa al combate. Este modelo puede ser usado por fans del deporte para conocer cuales son las probabilidades de victoria de cada peleador o en el mundo de las apuestas deportivas. Para ello utilizamos informaci칩n sobre peleas previas de cada peleador realizando medias ponderadas. Esta informaci칩n se obtiene de la p치gina oficial de la UFC y UFC Stats que tiene todos los combates hist칩ricos.

De forma interna referenciamos el primer modelo mencionado como P2 y el segundo como P1, no es necesario saberlo pero quiz치s facilita el entendimiento del repositorio y las carpetas.

### 2. Estructura del repositorio

- La carpeta data incluye un .txt con un link a Google Drive para descargarse la carpeta de data con los parquets procesados y los csv extra칤dos. Los archivos de esta carpeta se deben copiar dentro de la carpeta data ya creada.
- La carpeta mlruns incluye los diferentes experimentos realizados con diferentes modelos e hiperpar치metros.
- La carpeta src contiene todo el c칩digo. En esta carpeta encontramos diferentes carpetas con los m칩dulos y procesos utilizados para realizar el proyecto.
   * Extracci칩n:
      - `scraper_peleas.py`: Extrae informaci칩n de todos los combates por evento de la UFC de forma cronol칩gica, registramos el ganador, diferentes m칠tricas de cada pelea y los peleadores que pelean en ella. Para obtener la
        informaci칩n realizamos web-scraping de [UFC Stats](http://ufcstats.com/statistics/events/completed)
      - `scraper_peleadores.py`: Realiza web-scraping de informaci칩n de peleadores y sus im치genes las cuales usaremos en la p치gina web. La informaci칩n se extrae de [UFC](https://www.ufc.com/athletes/all)
      - `scraper_fecha_nacimiento.py`: Utilizado para extraer las fechas de naciemientos de los peleadores realizando web-scraping de una fuente de datos secundaria llamada [Tapology](https://www.tapology.com/).
   * Transformaci칩n:
      - `tratamiento_peleas.py`: Contiene una funci칩n que realiza una limpieza de las variables extra칤das para que sean m치s f치ciles de utilizar. Creamos algunas nuevas variables para que sean m치s 칰tiles para los modelos.
      - `tratamiento_peleadores.py`: Realiza la limpieza del dataset de peleadores para que las variables sean m치s usables.
      - `recordPeleas.py`: Calcula los records de cada peleador en el momento de las peleas. Es decir bas치ndose en el record actual de un peleador, el cual hemos guardado en el dataset de peleadores, vamos calculando el    record de cada peleador teniendo en cuenta si han perdido o ganado combates.
      - `nuevas_columnas_peleas_peleadores.py`: Este c칩digo contiene una funci칩n que crea nuevas variables algo m치s complejas bas치ndose tanto en las peleas de cada luchador como en su perfil de peleador. En este c칩digo se crean variables como un sistema de Puntos o las victorias o derrotas por cada m칠todo.
      - `peleasMediasPond.py`: Para cada pelea en el DataFrame de peleas sustituimos los datos reales de la pelea por las medias ponderadas de los 칰ltimos tres combates de cada peleador. En este caso las peleas cuyos peleadores no tengan m치s de tres combates son eliminados. Con esta funci칩n creamos el DataFrame que usaremos en el modelo de predicci칩n de peleas futuras.
      - `dfDif.py`: Crea un DataFrame con las variables como diferencias entre peleadores. Este DataFrame se crea a partir del DataFrame de medias ponderadas.
   * An치lisis:

        Para realizar an치lisis lo separamos en cuatro notebooks diferentes. En `analisis_peleas.ipynb` y `analisis_peleadores.ipynb` realizamos una exploraci칩n inicial de el dataset de peleas y peleadores con visualizaciones. Tambi칠n realizamos el notebook `analisis_peleas_ponderadas.ipynb`, este notebook lo usamos para ver las distribuciones de las variables en el dataset creado en el script de transformaciones con medias ponderadas. Tambi칠n estudiamos la correlaci칩n de las variables con la variable respuesta. Por 칰ltimo, tambi칠n realizamos `analisis_relaciones_variables_peleas.ipynb` en el cual estudiamos la relaci칩n de diferentes variables y sus correlaciones con las variables respuesta.
   * Models:

        Para realizar los diferentes modelos organizamos la carpeta model en tres carpetas. Una para los modelos con los datos de las peleas (P1), otra para los modelos de previos a las peleas (P2) y otra para los modelos de P2 con las variables como diferencias entre los peleadores. En cada uno de estas carpetas encontramos los modelos de `XGBoost`, `LogisticRegression` y `TreeClassifier` para cada modelo. En el caso de los modelos usando diferencias no usamos 치rboles de decisi칩n ya que estos los usamos para realizar un an치lisis exploratorio. En esta carpeta tambi칠n encontramos los notebooks para realizar las particiones de datos, respetando la secuencia temporal en caso de que sea necesario.
   * Evaluaci칩n:
 
        En cuanto a la carpeta de evaluaci칩n, encontramos dos subcarpetas que separan las evaluaciones por objetivo del modelo. Es decir, encontramos una carpeta para la evaluaci칩n de los modelos que predicen con datos de la pelea y otra carpeta para los modelos que predicen con datos previos a la pelea. En cada carpeta encontramos un notebook de evaluaci칩n, en el cual se comparan todos los modelos creados con ese objetivo en la fase de modelaje y se escoje el que obtiene mejores resultados. Tambi칠n encontramos otro notebook en el cual se pone a prueba a los modelos con nuevos datos m치s recientes para probar el funcionamiento de los modelos.

### 3. Como iniciar el entorno de desarrollo y sus dependencias

Para este proyecto hemos utilizado el gestor de entornos y dependencias [uv](https://github.com/astral-sh/uv), que simplifica considerablemente la configuraci칩n del entorno de desarrollo.

Pasos para comenzar:
Clona este repositorio:

```
git clone https://github.com/UCM-GIDIA-PD1/c2425-R4.git
cd c2425-R4
```
Instala las dependencias con el siguiente comando:

```
uv sync
```
Esto crear치 autom치ticamente un entorno virtual y descargar치 todas las dependencias especificadas.

Ejecuta scripts dentro del entorno con:

```
uv run script.py
```
Esto garantiza que el script se ejecute con la versi칩n correcta de Python y todas las dependencias necesarias, sin necesidad de activarlo manualmente.

游눠 Nota: Aseg칰rate de tener uv instalado antes de ejecutar estos comandos. Puedes encontrar instrucciones de instalaci칩n en el repositorio oficial de uv.

### 4. Instrucciones para ejecutar los scripts del proyecto

游눠 Nota: Es necesario haber inicializado el entorno virtual con sus dependencias previamente.

* Extracci칩n:

游눠 Nota: La extracci칩n puede tomar bastante tiempo. En caso de no querer realizarla existe un documento `data/data.txt` que contiene el link con una carpeta drive con los datos ya extra칤dos.

1. Este `main.py` realiza todo el proceso de extracci칩n. Se encuentra en la ruta `src\extraccion`. Este script se encarga de realizar web-scraping de todas las fuentes de datos que utilizamos. Para ello se debe ejecutar incluyendo como par치metro que datos queremos extraer que pueden ser "peleas", "peleadores" o "fechas". La ejecuci칩n del `main.py` es similar para los tres. Primero entramos a la carpeta donde se encuentra el script (se puede ejecutar tambi칠n desde la ra칤z incluyendo el path).
```
cd src
cd extraccion
```
2. Despu칠s ejecutamos el main con el par치metro que queramos extraer que puede ser peleas, peleadores o fechas.
```
uv run main.py peleas
```
3. En caso de que se quieran se pueden a침adir m치s parametros. Esos par치metros son diferentes en el caso de las diferentes fuentes, por ello explicamos para cada caso cuales son.
 * Peleas:
    * --pagina_inicio: Tipo entero, indica la p치gina por la que queremos empezar a extraer
    * --pagina_final: Tipo entero, indica la p치gina en la que queremos parar de extraer
 * Peleadores:
    * --pagina_inicio: Tipo entero, indica la p치gina por la que queremos empezar a extraer
    * --pagina_final: Tipo entero, indica la p치gina en la que queremos parar de extraer
  * Fechas:
    * --fila_inicio: Tipo entero, fila del dataset de peleadores por el que queremos empezar a extraer informaci칩n sobre el peleador adicional.
    * --fila_final: Tipo, entero, fila del dataset de peleadores en el que acaba la extracci칩n. Recomendamos extraer como mucho 200 filas cada tanda. Sino corremos el riesgo de que bloqueen la IP y no podamos continuar extrayendo durante un periodo de tiempo.

* Transformaci칩n:
1. Este `main.py` realiza la limpieza, transformacion y creaci칩n de variables que usaran los modelos para predecir los resultados. Se encuentra en la ruta `src\transformacion`. Primero entramos a la carpeta donde se encuentra el script (se puede ejecutar tambi칠n desde la ra칤z incluyendo el path).
```
cd src
cd transformacion
```
2. Despu칠s ejecutamos el main. Si no se a침aden par치metros extraer치 los datos `raw` de la carpeta `data`. En caso de que se quiera introducir un directorio de peleas o peleadores diferente se podr칤a cambiar usando el par치metro `--dir_peleas` o `dir_peleadores`.
```
uv ran main.py
``` 

### 5. Resultados y evaluaci칩n

* Modelo con datos de la pelea:

  En este caso el modelo que mejor desempe침o obtuvo fue el modelo `XGBoost`, realizando ajuste de hiperpar치metros usando `GridSearchCV`. A continuaci칩n mostramos las m칠tricas del mejor modelo comparado con el baseline (gana quien de m치s golpes):

  | Modelo | Accuracy | F1-Score |
  | --- | --- | --- |
  | XGBoost| |
  | Baseline | |


### 6. Equipo de desarrollo
 -  Andr칠s Fern치ndez Ortega
 -  Francisco Jos칠 Pastor Ruiz
 -  Mario Granados Guerrero
 -  Telmo Aracama Docampo
 -  Carlos Vallejo Ros
 -  Mateo Turati Dom칤nguez
   
Menci칩n especial y agradecimientos a nuestro profesor Antonio Alejandro S치nchez Ruiz-Granados por su constante ayuda y supervisi칩n a lo largo del desarrollo del proyecto.
